# Hybrid Search RAG (Production-Ready)

This repository contains a **production-ready Hybrid Search Retrieval-Augmented Generation (RAG) system** built using Python, FastAPI, Pinecone, and Llama 3 (served via Groq).

The system combines **sparse keyword-based retrieval (BM25)** with **dense vector retrieval (Pinecone)**to deliver accurate, low-latency, and scalable question answering.

The project is intentionally structured as a **modular Python codebase**, avoiding notebook-centric designs.


## ğŸš€ Key Features

- **Hybrid Retrieval**
  - Sparse retrieval using BM25 for exact keyword matching
  - Dense semantic retrieval using sentence embeddings stored in Pinecone
  - Weighted score fusion for improved recall and robustness

- **Production-Grade Architecture**
  - Modular Python files with clear separation of concerns
  - Config-driven design with environment-based secrets
  - Designed for extensibility (reranking, evaluation, APIs)

- **Low-Latency LLM Inference**
  - Llama 3 (`8B / 70B`) served via **Groq**
  - Fast response times suitable for real-time applications

- **API-First Design**
  - FastAPI-based REST service
  - Interactive Swagger documentation
  - CLI and API interfaces supported

## ğŸ“ Project Structure

```text
hybrid-search-rag/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config.py        # Central configuration & environment loading
â”‚   â”œâ”€â”€ api.py           # FastAPI application
â”‚   â”œâ”€â”€ data.py          # Document loading and chunking
â”‚   â”œâ”€â”€ retrieval.py     # BM25, dense, and hybrid retrievers
â”‚   â”œâ”€â”€ generation.py    # Prompting and Llama 3 (Groq) integration
â”‚   â”œâ”€â”€ pipeline.py      # End-to-end RAG orchestration
â”‚   â””â”€â”€ main.py          # CLI entry point
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ documents/       # Input text documents
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ build_pinecone_index.py  # One-time vector index builder
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
